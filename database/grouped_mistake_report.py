#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†ç»„é”™è¯¯æŠ¥å‘Šç”Ÿæˆå™¨ - æŒ‰ä¸­æ–‡åŸå¥ç›¸ä¼¼æ€§åˆ†ç»„ï¼Œç”Ÿæˆè€å¸ˆå‹å¥½çš„æŠ¥å‘Š
"""

import os
import json
import csv
import re
from datetime import datetime
from pathlib import Path
import sys
from collections import defaultdict
from difflib import SequenceMatcher

# æ·»åŠ configç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
config_dir = current_dir.parent / "config"
sys.path.append(str(config_dir))

from translation_rec_format_config import get_multi_output_config

class GroupedMistakeReporter:
    def __init__(self, base_dir):
        """
        åˆå§‹åŒ–åˆ†ç»„æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            base_dir (str): åŸºç¡€ç›®å½•è·¯å¾„
        """
        self.base_dir = Path(base_dir)
        self.config = get_multi_output_config()
        self.content_pattern = self.config["content_pattern"]
        self.error_data = []
        
        # è·å–å­—æ®µæ˜ å°„
        self.usage_output_config = self.config["output_types"]["usage_output"]
        self.field_mappings = self.usage_output_config["field_mappings"]
        
        # åˆ†ç»„æ•°æ®
        self.grouped_data = defaultdict(list)
        self.similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼
        
    def extract_content_from_raw(self, raw_content):
        """ä»raw_contentä¸­æå–JSONå†…å®¹"""
        try:
            match = re.search(self.content_pattern, raw_content)
            if not match:
                return None
                
            content_str = match.group(1)
            content_str = content_str.replace("\\'", "'")
            content_data = json.loads(content_str)
            return content_data
            
        except (json.JSONDecodeError, Exception) as e:
            print(f"å†…å®¹æå–é”™è¯¯: {e}")
            return None
    
    def clean_chinese_text(self, text):
        """æ¸…ç†ä¸­æ–‡åŸå¥ï¼Œå»æ‰å¼€å¤´çš„æ•°å­—æ ‡å·"""
        if not text:
            return text
        
        pattern = r'^\d+\.\s*'
        cleaned_text = re.sub(pattern, '', text)
        return cleaned_text.strip()
    
    def text_similarity(self, text1, text2):
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        return SequenceMatcher(None, text1, text2).ratio()
    
    def find_similar_group(self, text, existing_groups):
        """æŸ¥æ‰¾ç›¸ä¼¼çš„åˆ†ç»„"""
        for group_key in existing_groups:
            if self.text_similarity(text, group_key) >= self.similarity_threshold:
                return group_key
        return None
    
    def process_json_file(self, json_file_path):
        """å¤„ç†å•ä¸ªJSONæ–‡ä»¶"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            folder_name = data.get('folder_name', '')
            timestamp = data.get('timestamp', '')
            
            file_records = []
            
            for message in data.get('raw_messages', []):
                raw_content = message.get('raw_content', '')
                content_data = self.extract_content_from_raw(raw_content)
                
                if not content_data:
                    continue
                
                usage_output = content_data.get('usage_output', [])
                
                for idx, item in enumerate(usage_output, 1):
                    flag = item.get('flag', '')
                    chinese_txt = item.get('chinese_txt', '')
                    bracket_en_mistake = item.get('bracket_en_mistake', '')
                    
                    # æ¸…ç†ä¸­æ–‡åŸå¥
                    cleaned_chinese_txt = self.clean_chinese_text(chinese_txt)
                    
                    record = {
                        'folder_name': folder_name,
                        'timestamp': timestamp,
                        'json_file': json_file_path.name,
                        'sentence_index': idx,
                        'chinese_txt': cleaned_chinese_txt,
                        'bracket_en_mistake': bracket_en_mistake,
                        'flag': flag
                    }
                    
                    file_records.append(record)
            
            return file_records
            
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {json_file_path} æ—¶å‡ºé”™: {e}")
            return []
    
    def scan_all_folders(self):
        """æ‰«ææ‰€æœ‰å­æ–‡ä»¶å¤¹"""
        print(f"å¼€å§‹æ‰«æç›®å½•: {self.base_dir}")
        
        if not self.base_dir.exists():
            print(f"é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨: {self.base_dir}")
            return
        
        for folder_path in self.base_dir.iterdir():
            if not folder_path.is_dir():
                continue
            
            print(f"æ‰«ææ–‡ä»¶å¤¹: {folder_path.name}")
            
            json_files = list(folder_path.glob("*_response_cache_*.json"))
            
            if not json_files:
                print(f"è­¦å‘Šï¼šæ–‡ä»¶å¤¹ {folder_path.name} ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶")
                continue
            
            for json_file in json_files:
                print(f"å¤„ç†æ–‡ä»¶: {json_file.name}")
                records = self.process_json_file(json_file)
                self.error_data.extend(records)
        
        print(f"æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(self.error_data)} ä¸ªå¥å­è®°å½•")
    
    def group_by_similarity(self):
        """æŒ‰ç›¸ä¼¼åº¦åˆ†ç»„æ•°æ®"""
        print("å¼€å§‹æŒ‰ç›¸ä¼¼åº¦åˆ†ç»„...")
        
        for record in self.error_data:
            chinese_txt = record['chinese_txt']
            if not chinese_txt:
                continue
            
            # æŸ¥æ‰¾ç›¸ä¼¼çš„åˆ†ç»„
            similar_group = self.find_similar_group(chinese_txt, self.grouped_data.keys())
            
            if similar_group:
                # æ·»åŠ åˆ°ç°æœ‰åˆ†ç»„
                self.grouped_data[similar_group].append(record)
            else:
                # åˆ›å»ºæ–°åˆ†ç»„
                self.grouped_data[chinese_txt].append(record)
        
        print(f"åˆ†ç»„å®Œæˆï¼Œå…±ç”Ÿæˆ {len(self.grouped_data)} ä¸ªåˆ†ç»„")
    
    def generate_teacher_report(self):
        """ç”Ÿæˆé€‚åˆè€å¸ˆæŸ¥çœ‹çš„æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ç”ŸæˆCSVæŠ¥å‘Š
        csv_file = self.base_dir / f"åˆ†ç»„é”™è¯¯æŠ¥å‘Š_{timestamp}.csv"
        self.generate_csv_report(csv_file)
        
        # 2. ç”Ÿæˆè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š
        txt_file = self.base_dir / f"åˆ†ç»„é”™è¯¯è¯¦ç»†æŠ¥å‘Š_{timestamp}.txt"
        self.generate_detailed_text_report(txt_file)
        
        # 3. ç”Ÿæˆç®€æ´æ±‡æ€»æŠ¥å‘Š
        summary_file = self.base_dir / f"é”™è¯¯æ±‡æ€»æŠ¥å‘Š_{timestamp}.txt"
        self.generate_summary_report(summary_file)
        
        print(f"\næ‰€æœ‰æŠ¥å‘Šå·²ç”Ÿæˆ:")
        print(f"1. CSVæŠ¥å‘Š: {csv_file}")
        print(f"2. è¯¦ç»†æŠ¥å‘Š: {txt_file}")
        print(f"3. æ±‡æ€»æŠ¥å‘Š: {summary_file}")
    
    def generate_csv_report(self, csv_file):
        """ç”ŸæˆCSVæ ¼å¼æŠ¥å‘Š"""
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            fieldnames = [
                'åˆ†ç»„åºå·', 'ä¸­æ–‡åŸå¥', 'æ€»æ‰¹æ”¹ä»½æ•°', 'é”™è¯¯ä»½æ•°', 'æ­£ç¡®ä»½æ•°', 
                'é”™è¯¯ç‡(%)', 'å¸¸è§é”™è¯¯è¡¨è¾¾', 'æ¶‰åŠå­¦ç”Ÿ'
            ]
            
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for idx, (group_key, records) in enumerate(sorted(self.grouped_data.items()), 1):
                total_count = len(records)
                false_count = len([r for r in records if r['flag'] == 'false'])
                true_count = total_count - false_count
                error_rate = (false_count / total_count * 100) if total_count > 0 else 0
                
                # æ”¶é›†é”™è¯¯è¡¨è¾¾
                mistakes = [r['bracket_en_mistake'] for r in records if r['flag'] == 'false' and r['bracket_en_mistake']]
                common_mistakes = ', '.join(list(set(mistakes))[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªä¸åŒçš„é”™è¯¯
                
                # æ¶‰åŠå­¦ç”Ÿ
                students = list(set([r['folder_name'] for r in records]))
                students_str = ', '.join(students[:5])  # æœ€å¤šæ˜¾ç¤º5ä¸ªå­¦ç”Ÿåå­—
                if len(students) > 5:
                    students_str += f" ç­‰{len(students)}äºº"
                
                row = {
                    'åˆ†ç»„åºå·': idx,
                    'ä¸­æ–‡åŸå¥': group_key[:50] + "..." if len(group_key) > 50 else group_key,
                    'æ€»æ‰¹æ”¹ä»½æ•°': total_count,
                    'é”™è¯¯ä»½æ•°': false_count,
                    'æ­£ç¡®ä»½æ•°': true_count,
                    'é”™è¯¯ç‡(%)': f"{error_rate:.1f}",
                    'å¸¸è§é”™è¯¯è¡¨è¾¾': common_mistakes,
                    'æ¶‰åŠå­¦ç”Ÿ': students_str
                }
                writer.writerow(row)
    
    def generate_detailed_text_report(self, txt_file):
        """ç”Ÿæˆè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š"""
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("è‹±è¯­ç¿»è¯‘æ‰¹æ”¹åˆ†ç»„é”™è¯¯è¯¦ç»†æŠ¥å‘Š\n")
            f.write("=" * 80 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ•°æ®æ¥æº: {self.base_dir}\n")
            f.write(f"æ€»åˆ†ç»„æ•°: {len(self.grouped_data)}\n")
            f.write(f"æ€»å¥å­æ•°: {len(self.error_data)}\n")
            
            # æ•´ä½“ç»Ÿè®¡
            total_false = len([r for r in self.error_data if r['flag'] == 'false'])
            total_true = len(self.error_data) - total_false
            overall_accuracy = (total_true / len(self.error_data) * 100) if self.error_data else 0
            
            f.write(f"æ€»é”™è¯¯æ•°: {total_false}\n")
            f.write(f"æ€»æ­£ç¡®æ•°: {total_true}\n")
            f.write(f"æ•´ä½“æ­£ç¡®ç‡: {overall_accuracy:.1f}%\n")
            f.write("\n" + "=" * 80 + "\n\n")
            
            # æŒ‰é”™è¯¯ç‡æ’åºåˆ†ç»„
            sorted_groups = sorted(
                self.grouped_data.items(), 
                key=lambda x: len([r for r in x[1] if r['flag'] == 'false']) / len(x[1]), 
                reverse=True
            )
            
            for idx, (group_key, records) in enumerate(sorted_groups, 1):
                total_count = len(records)
                false_count = len([r for r in records if r['flag'] == 'false'])
                true_count = total_count - false_count
                error_rate = (false_count / total_count * 100) if total_count > 0 else 0
                
                f.write(f"ã€åˆ†ç»„ {idx}ã€‘\n")
                f.write(f"ä¸­æ–‡åŸå¥: {group_key}\n")
                f.write(f"æ‰¹æ”¹ç»Ÿè®¡: æ€»è®¡ {total_count} ä»½ï¼Œé”™è¯¯ {false_count} ä»½ï¼Œæ­£ç¡® {true_count} ä»½\n")
                f.write(f"é”™è¯¯ç‡: {error_rate:.1f}%\n")
                
                # é”™è¯¯è¡¨è¾¾ç»Ÿè®¡
                mistakes = {}
                for record in records:
                    if record['flag'] == 'false' and record['bracket_en_mistake']:
                        mistake = record['bracket_en_mistake']
                        mistakes[mistake] = mistakes.get(mistake, 0) + 1
                
                if mistakes:
                    f.write("é”™è¯¯è¡¨è¾¾ç»Ÿè®¡:\n")
                    for mistake, count in sorted(mistakes.items(), key=lambda x: x[1], reverse=True):
                        f.write(f"  - '{mistake}': {count} æ¬¡\n")
                
                
                # æ¶‰åŠå­¦ç”Ÿ - åªæ˜¾ç¤ºç¿»è¯‘é”™è¯¯çš„å­¦ç”Ÿ
                error_students = list(set([r['folder_name'] for r in records if r['flag'] == 'false']))
                f.write(f"æ¶‰åŠå­¦ç”Ÿ ({len(error_students)} äºº): {', '.join(error_students)}\n")
                f.write("-" * 60 + "\n\n")
    
    def generate_summary_report(self, summary_file):
        """ç”Ÿæˆç®€æ´æ±‡æ€»æŠ¥å‘Š"""
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("è‹±è¯­ç¿»è¯‘æ‰¹æ”¹é”™è¯¯æ±‡æ€»æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n")
            f.write(f"æŠ¥å‘Šæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Top 10 é”™è¯¯ç‡æœ€é«˜çš„åˆ†ç»„
            sorted_groups = sorted(
                self.grouped_data.items(), 
                key=lambda x: len([r for r in x[1] if r['flag'] == 'false']) / len(x[1]), 
                reverse=True
            )
            
            f.write("âŒ é”™è¯¯ç‡æœ€é«˜çš„10ä¸ªå¥å­ç±»å‹:\n")
            f.write("-" * 40 + "\n")
            
            for idx, (group_key, records) in enumerate(sorted_groups[:10], 1):
                total_count = len(records)
                false_count = len([r for r in records if r['flag'] == 'false'])
                error_rate = (false_count / total_count * 100) if total_count > 0 else 0
                
                # æœ€å¸¸è§çš„é”™è¯¯
                mistakes = [r['bracket_en_mistake'] for r in records if r['flag'] == 'false' and r['bracket_en_mistake']]
                common_mistake = max(set(mistakes), key=mistakes.count) if mistakes else "æ— "
                
                f.write(f"{idx}. é”™è¯¯ç‡: {error_rate:.1f}% ({false_count}/{total_count})\n")
                f.write(f"   å¥å­: {group_key[:60]}{'...' if len(group_key) > 60 else ''}\n")
                f.write(f"   å¸¸è§é”™è¯¯: {common_mistake}\n\n")
            
            # æ•´ä½“ç»Ÿè®¡
            f.write("ğŸ“Š æ•´ä½“ç»Ÿè®¡:\n")
            f.write("-" * 20 + "\n")
            total_students = len(set([r['folder_name'] for r in self.error_data]))
            total_false = len([r for r in self.error_data if r['flag'] == 'false'])
            total_true = len(self.error_data) - total_false
            overall_accuracy = (total_true / len(self.error_data) * 100) if self.error_data else 0
            
            f.write(f"å‚ä¸å­¦ç”Ÿæ•°: {total_students} äºº\n")
            f.write(f"å¥å­åˆ†ç»„æ•°: {len(self.grouped_data)} ç»„\n")
            f.write(f"æ€»å¥å­æ•°: {len(self.error_data)} å¥\n")
            f.write(f"æ­£ç¡®æ•°: {total_true} å¥\n")
            f.write(f"é”™è¯¯æ•°: {total_false} å¥\n")
            f.write(f"æ•´ä½“æ­£ç¡®ç‡: {overall_accuracy:.1f}%\n")
    
    def print_quick_summary(self):
        """æ‰“å°å¿«é€Ÿæ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ åˆ†ç»„é”™è¯¯æŠ¥å‘Šæ‘˜è¦")
        print("=" * 60)
        
        total_groups = len(self.grouped_data)
        total_sentences = len(self.error_data)
        total_false = len([r for r in self.error_data if r['flag'] == 'false'])
        total_students = len(set([r['folder_name'] for r in self.error_data]))
        
        print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"   å‚ä¸å­¦ç”Ÿ: {total_students} äºº")
        print(f"   å¥å­åˆ†ç»„: {total_groups} ç»„")
        print(f"   æ€»å¥å­æ•°: {total_sentences} å¥")
        print(f"   é”™è¯¯å¥å­: {total_false} å¥")
        print(f"   æ•´ä½“æ­£ç¡®ç‡: {(total_sentences-total_false)/total_sentences*100:.1f}%")
        
        # æ˜¾ç¤ºé”™è¯¯ç‡æœ€é«˜çš„5ä¸ªåˆ†ç»„
        sorted_groups = sorted(
            self.grouped_data.items(), 
            key=lambda x: len([r for r in x[1] if r['flag'] == 'false']) / len(x[1]), 
            reverse=True
        )
        
        print(f"\nğŸ”´ é”™è¯¯ç‡æœ€é«˜çš„5ä¸ªå¥å­ç±»å‹:")
        for idx, (group_key, records) in enumerate(sorted_groups[:5], 1):
            total_count = len(records)
            false_count = len([r for r in records if r['flag'] == 'false'])
            error_rate = (false_count / total_count * 100) if total_count > 0 else 0
            
            print(f"   {idx}. {error_rate:.1f}% - {group_key[:40]}{'...' if len(group_key) > 40 else ''}")


def main():
    """ä¸»å‡½æ•°"""
    base_dir = r"E:\zhenzhen_eng_coze\example\ç¿»è¯‘\ä½œä¸šå†…å®¹_ç¿»è¯‘_Download_1_50"
    
    print("ğŸ” å¼€å§‹ç”Ÿæˆåˆ†ç»„é”™è¯¯æŠ¥å‘Š...")
    
    reporter = GroupedMistakeReporter(base_dir)
    
    # 1. æ‰«ææ•°æ®
    reporter.scan_all_folders()
    
    # 2. æŒ‰ç›¸ä¼¼åº¦åˆ†ç»„
    reporter.group_by_similarity()
    
    # 3. æ‰“å°å¿«é€Ÿæ‘˜è¦
    reporter.print_quick_summary()
    
    # 4. ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
    reporter.generate_teacher_report()
    
    print(f"\nâœ… æ‰€æœ‰æŠ¥å‘Šå·²ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“ æ–‡ä»¶ä¿å­˜ä½ç½®: {base_dir}")


if __name__ == "__main__":
    main()
